## Papers related to generated code detection

Regarding the rising era of LLMs, it is become challenging to develop tools and approaches to detect generated contents. The application is various specially in the education field to attest the autorship of the student's works, in the scientific domain, etc. In this repository, we gather all papers related to generated text detection and specially on code detection.

The following repository will be structured as sub-folders following these topics :

- [üåü Generated Code Detection](#intro)
- [üìú Papers](#papers)
    - [üè∑Ô∏è Tagset](#tagset)
    - [üéØ The List](#list)
- [üß∞ Resources](#resources)
    - [üìä Datasets](#datasets)
    - [üõ†Ô∏è Tools](#tools)
- [üö© Citation](#citation)
- [üéâ Contribution](#contribution)
- [ü§ù Acknowledgement](#acknowledgement)


<a id="intro"></a>
## üåü Generated Code Detection


<a id="papers"></a>
## üìú Papers

<a id="tagset"></a>
### üè∑Ô∏è Tagset

In this paper list, we tag each paper with one or more labels defined in the table below. These tags serve the purpose of facilitating the related work searching.

| Category | Explanation |
|----------|-------------|
| ![](https://img.shields.io/badge/Analysis-green) | The paper propose a analyse of the existing approach on the generated code detection and the potential features to consider to distinguish human writing from generated code.*. |
| ![](https://img.shields.io/badge/Tools-brown) | The paper propose a tool to detect generated code or to classify a human writing and generated code. This tag will be follow by a category of the proposed approach*. |
| ![](https://img.shields.io/badge/Dataset-blue) | The paper propose a dataset for human_writing / generated code classification. Most of these dataset is constituted by coding problems / contests associated with human writing and generated code (Depending of the model).* |
| ![](https://img.shields.io/badge/Machine_Learning-green) | The paper proposed an approach based on Machine Learning applied to code features classification following the nature of the submited code.* |
| ![](https://img.shields.io/badge/Watermarking-cyan) | The paper proposed an approach based on code watermarking. These approches will imply to modify the generated of to force the model to adopt a certain code stylometric that can be detected.* |


<a id="list"></a>
### üéØ The List

> [!Note]
> The list is sorted by the date of the first time the paper was released.

1. **Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education** (IEEE/ACM 2024) ![](https://img.shields.io/badge/Analysis-green)<br />
    *PAN, Wei Hung, CHOK, Ming Jie, WONG, Jonathan Leong Shan, Shin, Yung Xin, Poon, Yeong Shian*
    [[paper](https://ieeexplore.ieee.org/document/10554754/)]
    <details><summary><b>Abstract</b></summary>
    Educators are increasingly concerned about the usage of Large Language Models (LLMs) such as ChatGPT in programming education, particularly regarding the potential exploitation of imperfections in Artificial Intelligence Generated Content (AIGC) Detectors for academic misconduct. In this paper, we present an empirical study where the LLM is examined for its attempts to bypass detection by AIGC Detectors. This is achieved by generating code in response to a given question using different variants. We collected a dataset comprising 5,069 samples, with each sample consisting of a textual description of a coding problem and its corresponding human-written Python solution codes. These samples were obtained from various sources, including 80 from Quescol, 3,264 from Kaggle, and 1,725 from Leet-Code. From the dataset, we created 13 sets of code problem variant prompts, which were used to instruct ChatGPT to generate the outputs. Subsequently, we assessed the performance of five AIGC detectors. Our results demonstrate that existing AIGC Detectors perform poorly in distinguishing between human-written code and AI-generated code.
    </details>

1. **Discriminating Human-authored from ChatGPT-Generated Code Via Discernable Feature Analysis** (ISSREW 2023) ![](https://img.shields.io/badge/Analysis-green) ![](https://img.shields.io/badge/Dataset-blue)<br />
    *Ke Li, Sheng Hong, Cai Fu, Yunhe Zhang, Ming Liu*
    [[paper](https://ieeexplore.ieee.org/document/10301301)]
    <details><summary><b>Abstract</b></summary>
    The ubiquitous adoption of Large Language Generation Models (LLMs) in programming has highlighted the importance of distinguishing between human-written code and code generated by intelligent models. This paper specifically aims to distinguish ChatGPT-generated code from human-generated code. Our investigation reveals differences in programming style, technical level and readability between these two sources. Consequently, we develop a discriminative feature set for differentiation and evaluate its effectiveness through ablation experiments. In addition, we develop a dataset cleaning technique using temporal and spatial segmentation to mitigate dataset scarcity and ensure high quality, uncontaminated datasets. To further enrich the data resources, we apply "code transformation", "feature transformation" and "feature adaptation" techniques, generating a rich dataset of 100,000 lines of ChatGPT-generated code. The main contributions of our research include: proposing a discriminative feature set that yields high accuracy in distinguishing ChatGPT-generated code from human-authored code in binary classification tasks; devising methods for generating rich ChatGPT-generated code; and introducing a dataset cleansing strategy that extracts pristine, high-quality code datasets from open-source repositories, thereby achieving exceptional accuracy in code authorship attribution tasks.
    </details>

1. **ACW: Enhancing Traceability of AI-Generated Codes Based on Watermarking** (arXiv Aug 2024) ![](https://img.shields.io/badge/Watermarking-cyan) <br />
    *Boquan Li, Mengdi Zhang, Peixin Zhang, Jun Sun, Xingmei Wang*
    [[paper](https://arxiv.org/abs/2402.07518)]
    <details><summary><b>Abstract</b></summary>
    With the development of large language models, multiple AIs have become available for code generation (such as ChatGPT and StarCoder) and are adopted widely. It is often desirable to know whether a piece of code is generated by AI, and furthermore, which AI is the author. For instance, if a certain version of AI is known to generate vulnerable codes, it is particularly important to know the creator. Watermarking is broadly considered a promising solution and is successfully applied for identifying AI-generated text. However, existing efforts on watermarking AI-generated codes are far from ideal, and pose more challenges than watermarking general text due to limited flexibility and encoding space. In this work, we propose ACW (AI Code Watermarking), a novel method for watermarking AI-generated codes. The key idea of ACW is to selectively apply a set of carefully-designed semantic-preserving, idempotent code transformations, whose presence (or absence) allows us to determine the existence of watermarks. It is efficient as it requires no training or fine-tuning and works in a black-box manner. Our experimental results show that ACW is effective (i.e., achieving high accuracy on detecting AI-generated codes and extracting watermarks) as well as resilient, significantly outperforming existing approaches.
    </details>


1. **Automatic Detection of LLM-generated Code: A Case Study of Claude 3 Haiku** (arXiv Sept 2024) ![](https://img.shields.io/badge/Analysis-green) ![](https://img.shields.io/badge/Machine_Learning-green) <br />
    *Musfiqur Rahman, SayedHassan Khatoonabadi, Ahmad Abdellatif, Emad Shihab
    [[paper](https://arxiv.org/abs/2409.01382)]
    <details><summary><b>Abstract</b></summary>
   Using Large Language Models (LLMs) has gained popularity among software developers for generating source code. However, the use of LLM-generated code can introduce risks of adding suboptimal, defective, and vulnerable code. This makes it necessary to devise methods for the accurate detection of LLM-generated code. Toward this goal, we perform a case study of Claude 3 Haiku (or Claude 3 for brevity) on CodeSearchNet dataset. We divide our analyses into two parts: function-level and class-level. We extract 22 software metric features, such as Code Lines and Cyclomatic Complexity, for each level of granularity. We then analyze code snippets generated by Claude 3 and their human-authored counterparts using the extracted features to understand how unique the code generated by Claude 3 is. In the following step, we use the unique characteristics of Claude 3-generated code to build Machine Learning (ML) models and identify which features of the code snippets make them more detectable by ML models. Our results indicate that Claude 3 tends to generate longer functions, but shorter classes than humans, and this characteristic can be used to detect Claude 3-generated code with ML models with 82% and 66% accuracies for function-level and class-level snippets, respectively.
    </details>

